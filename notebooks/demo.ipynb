{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# YOLOv5 GradCAM++ Demo for Anterior Segment Disease Classification\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kitaguchi77/yolov5-gradcam-corneai/blob/main/notebooks/demo.ipynb)\n\nThis notebook demonstrates how to use the YOLOv5 GradCAM++ and Cut-and-Paste validation tools for anterior segment disease classification analysis.\n\n**Note**: This notebook is designed to run on Google Colab. If running locally, adjust the setup steps accordingly."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Notes for Google Colab Users\n",
    "\n",
    "1. **Model Weights**: You need to provide YOLOv5 model weights trained on corneal images\n",
    "   - Upload directly when prompted, or\n",
    "   - Place in Google Drive at: `/content/drive/MyDrive/YOLOv5_weights/last.pt`\n",
    "\n",
    "2. **Test Images**: For actual analysis, you need slit-lamp photographs\n",
    "   - The demo creates placeholder data for illustration purposes\n",
    "\n",
    "3. **CPU Recommended**: Based on the reference implementation, CPU gives more consistent results than GPU\n",
    "\n",
    "4. **Dependencies**: All required packages are installed automatically in the setup cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check if running on Google Colab\nimport sys\nIN_COLAB = 'google.colab' in sys.modules\n\nif IN_COLAB:\n    print(\"Running on Google Colab\")\n    \n    # Mount Google Drive\n    from google.colab import drive\n    drive.mount('/content/drive')\n    \n    # Change to content directory\n    %cd /content\n    \n    # Install required packages directly (based on reference_code.txt)\n    print(\"\\nInstalling required packages...\")\n    !pip uninstall deep_utils -y\n    !pip install -U git+https://github.com/pooya-mohammadi/deep_utils.git --q\n    !pip install torch torchvision --q\n    !pip install opencv-python --q\n    !pip install matplotlib pandas numpy tqdm scipy statsmodels seaborn plotly --q\n    !pip install PyYAML Pillow scikit-image --q\n    \n    # Clone the yolov5-gradcam repository\n    print(\"\\nCloning yolov5-gradcam repository...\")\n    !git clone https://github.com/pooya-mohammadi/yolov5-gradcam\n    \n    # Also clone our repository for the custom modules\n    print(\"\\nCloning project repository...\")\n    !git clone https://github.com/kitaguchi77/yolov5-gradcam-corneai.git\n    \n    # Set up paths\n    import os\n    os.chdir('/content/yolov5-gradcam-corneai')\n    \n    # Clone YOLOv5 (CorneAI fork)\n    if not os.path.exists('yolov5'):\n        !git clone https://github.com/modafone/corneaai.git yolov5\n    \n    print(\"\\nSetup complete!\")\n    \n    # Optional: Upload model weights to Colab\n    from google.colab import files\n    print(\"\\nPlease upload your YOLOv5 model weights file (or skip to use sample data):\")\n    print(\"Note: You can also place the weights file in your Google Drive\")\n    \n    use_upload = input(\"Upload weights file? (y/n): \")\n    if use_upload.lower() == 'y':\n        uploaded = files.upload()\n        if uploaded:\n            weights_filename = list(uploaded.keys())[0]\n            !mkdir -p models\n            !mv {weights_filename} models/\n            print(f\"Model weights saved to models/{weights_filename}\")\n    else:\n        print(\"Skipping upload - you can specify a Google Drive path later\")\n        weights_filename = None\nelse:\n    print(\"Running locally - skipping Colab setup\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the reference implementation approach\n",
    "\n",
    "Based on the reference code from https://github.com/pooya-mohammadi/yolov5-gradcam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Use sample data from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Use Google Drive paths or download sample data\n",
    "if IN_COLAB:\n",
    "    # Option 1: Use model from Google Drive (if you have it there)\n",
    "    gdrive_model_path = \"/content/drive/MyDrive/YOLOv5_weights/last.pt\"  # Update this path\n",
    "    \n",
    "    if os.path.exists(gdrive_model_path):\n",
    "        print(f\"Found model in Google Drive: {gdrive_model_path}\")\n",
    "        weights_filename = \"last.pt\"\n",
    "        !mkdir -p models\n",
    "        !cp {gdrive_model_path} models/\n",
    "    elif weights_filename is None:\n",
    "        # Option 2: Download a sample model (you would need to host this)\n",
    "        print(\"No model found. Using CPU device for demo...\")\n",
    "        print(\"Note: For actual inference, you need to provide model weights\")\n",
    "        \n",
    "    # Create sample data directory\n",
    "    !mkdir -p data/sample_images\n",
    "    \n",
    "    # For demo purposes, we'll create synthetic sample data\n",
    "    print(\"\\nCreating sample data for demonstration...\")\n",
    "    \n",
    "    # Note: In a real scenario, you would download actual cornea images\n",
    "    # For now, we'll create placeholder entries\n",
    "    import pandas as pd\n",
    "    \n",
    "    sample_data = []\n",
    "    classes = [\"Normal\", \"Infectious keratitis\", \"Non-infectious keratitis\", \"Scar\", \"Tumor\", \n",
    "               \"Deposit\", \"APAC\", \"Lens opacity\", \"Bullous keratopathy\"]\n",
    "    \n",
    "    # Create dummy entries (in practice, these would be real image paths)\n",
    "    for i in range(10):\n",
    "        sample_data.append({\n",
    "            'image_path': f'data/sample_images/sample_{i}.jpg',\n",
    "            'label': i % 9,\n",
    "            'class_name': classes[i % 9]\n",
    "        })\n",
    "    \n",
    "    df_sample = pd.DataFrame(sample_data)\n",
    "    df_sample.to_csv('data/sample_images.csv', index=False)\n",
    "    print(\"Sample data CSV created\")\n",
    "    \n",
    "    # Note about the reference implementation\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"NOTE: This notebook is based on the reference implementation\")\n",
    "    print(\"from: https://github.com/pooya-mohammadi/yolov5-gradcam\")\n",
    "    print(\"For production use, ensure you have:\")\n",
    "    print(\"1. Actual YOLOv5 model weights trained on cornea images\")\n",
    "    print(\"2. Real test images from slit-lamp photography\")\n",
    "    print(\"3. Proper annotations for cut-and-paste validation\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# For Colab, we need to add the correct paths\n",
    "if IN_COLAB:\n",
    "    # Add paths for the cloned repositories\n",
    "    sys.path.append('/content/yolov5-gradcam-cornea/Code')\n",
    "    sys.path.append('/content/yolov5-gradcam')\n",
    "    \n",
    "    # Also add the yolov5 directory\n",
    "    sys.path.append('/content/yolov5-gradcam-cornea/Code/yolov5')\n",
    "\n",
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from IPython.display import Image, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import torch\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# For Colab, we'll create simplified versions of the modules if they're not available\n",
    "try:\n",
    "    from models.yolov5_model import YOLOv5Model\n",
    "    from models.yolov5_gradcam import YOLOv5GradCAMPlusPlus\n",
    "    from validation.cut_and_paste import CutAndPasteValidator\n",
    "    from utils.data_loader import DataLoader\n",
    "    from utils.metrics import MetricsCalculator\n",
    "    from analysis.visualization import Visualizer\n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "    print(\"Note: Some modules may not be available. Using simplified demo mode.\")\n",
    "    \n",
    "    # Define placeholder classes for demo\n",
    "    class YOLOv5Model:\n",
    "        def __init__(self, weights_path, device='cpu'):\n",
    "            self.weights_path = weights_path\n",
    "            self.device = device\n",
    "            self.class_names = {\n",
    "                0: \"Normal\",\n",
    "                1: \"Infectious keratitis\", \n",
    "                2: \"Non-infectious keratitis\",\n",
    "                3: \"Scar\",\n",
    "                4: \"Tumor\",\n",
    "                5: \"Deposit\",\n",
    "                6: \"APAC\",\n",
    "                7: \"Lens opacity\",\n",
    "                8: \"Bullous keratopathy\"\n",
    "            }\n",
    "            print(f\"Demo mode: YOLOv5Model initialized with {weights_path}\")\n",
    "\n",
    "# Set matplotlib backend for Colab\n",
    "if IN_COLAB:\n",
    "    %matplotlib inline\n",
    "\n",
    "print(\"Import complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "if IN_COLAB:\n",
    "    # Colab paths - check if we have a weights file\n",
    "    if 'weights_filename' in locals() and weights_filename:\n",
    "        WEIGHTS_PATH = f\"models/{weights_filename}\"\n",
    "    else:\n",
    "        # Try Google Drive path\n",
    "        WEIGHTS_PATH = \"/content/drive/MyDrive/YOLOv5_weights/last.pt\"\n",
    "        \n",
    "    TEST_DATA_PATH = \"data/sample_images.csv\"\n",
    "    SAMPLE_IMAGES_DIR = \"data/sample_images\"\n",
    "    \n",
    "    # Check if weights exist\n",
    "    import os\n",
    "    if not os.path.exists(WEIGHTS_PATH):\n",
    "        print(f\"Warning: Model weights not found at {WEIGHTS_PATH}\")\n",
    "        print(\"You can:\")\n",
    "        print(\"1. Upload your model weights using the file upload in the setup cell\")\n",
    "        print(\"2. Place your weights in Google Drive at: /content/drive/MyDrive/YOLOv5_weights/\")\n",
    "        print(\"3. Continue in demo mode without actual inference\")\n",
    "        WEIGHTS_PATH = None\n",
    "else:\n",
    "    # Local paths - update these\n",
    "    WEIGHTS_PATH = \"path/to/yolov5_weights.pt\"\n",
    "    TEST_DATA_PATH = \"path/to/test_data.csv\"\n",
    "\n",
    "# Device selection - based on reference_code.txt, CPU is recommended for consistency\n",
    "DEVICE = \"cpu\"  # CPU recommended for reproducible results\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(\"Note: Based on the reference implementation, CPU is recommended for consistent results\")\n",
    "\n",
    "# Load model if weights are available\n",
    "if WEIGHTS_PATH and os.path.exists(WEIGHTS_PATH):\n",
    "    print(f\"\\nLoading YOLOv5 model from {WEIGHTS_PATH}...\")\n",
    "    try:\n",
    "        model = YOLOv5Model(WEIGHTS_PATH, device=DEVICE)\n",
    "        print(\"Model loaded successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        model = None\n",
    "else:\n",
    "    print(\"\\nNo model weights available - running in demo mode\")\n",
    "    model = None\n",
    "\n",
    "# Load or create test data\n",
    "print(f\"\\nLoading test data...\")\n",
    "\n",
    "try:\n",
    "    data_loader = DataLoader()\n",
    "    test_images = data_loader.load_image_list(TEST_DATA_PATH)\n",
    "    print(f\"Loaded {len(test_images)} test images\")\n",
    "except:\n",
    "    print(\"Using demo data\")\n",
    "    # Create demo data structure\n",
    "    from types import SimpleNamespace\n",
    "    test_images = [\n",
    "        SimpleNamespace(\n",
    "            image_path=f\"sample_{i}.jpg\",\n",
    "            label=i % 9,\n",
    "            class_name=[\"Normal\", \"Infectious keratitis\", \"Non-infectious keratitis\", \n",
    "                       \"Scar\", \"Tumor\", \"Deposit\", \"APAC\", \"Lens opacity\", \n",
    "                       \"Bullous keratopathy\"][i % 9]\n",
    "        ) for i in range(5)\n",
    "    ]\n",
    "\n",
    "if model:\n",
    "    print(f\"\\nClasses: {list(model.class_names.values())}\")\n",
    "else:\n",
    "    print(\"\\nDisease classes:\")\n",
    "    for i in range(9):\n",
    "        print(f\"{i}: {test_images[0].class_name if i == 0 else test_images[i % len(test_images)].class_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Single Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample image\n",
    "if len(test_images) > 0:\n",
    "    sample_image = test_images[0]\n",
    "    print(f\"Analyzing: {sample_image.image_path}\")\n",
    "    print(f\"True class: {sample_image.class_name}\")\n",
    "    \n",
    "    # Display the image if in Colab\n",
    "    if IN_COLAB:\n",
    "        from IPython.display import Image as IPImage\n",
    "        display(IPImage(sample_image.image_path, width=400))\n",
    "    \n",
    "    # Run inference\n",
    "    results = model.predict(sample_image.image_path)\n",
    "    \n",
    "    if len(results['classes']) > 0:\n",
    "        pred_class_idx = results['classes'][results['scores'].argmax()]\n",
    "        pred_class_name = model.class_names[pred_class_idx]\n",
    "        confidence = results['scores'].max()\n",
    "        \n",
    "        print(f\"\\nPredicted class: {pred_class_name} (confidence: {confidence:.3f})\")\n",
    "    else:\n",
    "        print(\"\\nNo detection\")\n",
    "        pred_class_idx = 0  # Default to first class for demo\n",
    "else:\n",
    "    print(\"No test images loaded. Please check your data path.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo mode message if no model is loaded\n",
    "if len(test_images) > 0 and model is None:\n",
    "    print(\"=\"*60)\n",
    "    print(\"DEMO MODE: No model loaded\")\n",
    "    print(\"This section shows what the analysis would look like with a real model\")\n",
    "    print(\"To run actual inference, please provide model weights\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create dummy results for demonstration\n",
    "    sample_image = test_images[0]\n",
    "    print(f\"\\nDemo image: {sample_image.image_path}\")\n",
    "    print(f\"True class: {sample_image.class_name}\")\n",
    "    \n",
    "    # Simulate prediction\n",
    "    pred_class_idx = 1  # Demo prediction\n",
    "    pred_class_name = \"Infectious keratitis\"\n",
    "    confidence = 0.89\n",
    "    \n",
    "    print(f\"\\nSimulated prediction: {pred_class_name} (confidence: {confidence:.3f})\")\n",
    "    \n",
    "elif len(test_images) > 0 and model is not None:\n",
    "    # Actual inference with real model\n",
    "    sample_image = test_images[0]\n",
    "    print(f\"Analyzing: {sample_image.image_path}\")\n",
    "    print(f\"True class: {sample_image.class_name}\")\n",
    "    \n",
    "    # Display the image if it exists and in Colab\n",
    "    if IN_COLAB and os.path.exists(sample_image.image_path):\n",
    "        from IPython.display import Image as IPImage\n",
    "        display(IPImage(sample_image.image_path, width=400))\n",
    "    \n",
    "    # Run inference\n",
    "    results = model.predict(sample_image.image_path)\n",
    "    \n",
    "    if len(results['classes']) > 0:\n",
    "        pred_class_idx = results['classes'][results['scores'].argmax()]\n",
    "        pred_class_name = model.class_names[pred_class_idx]\n",
    "        confidence = results['scores'].max()\n",
    "        \n",
    "        print(f\"\\nPredicted class: {pred_class_name} (confidence: {confidence:.3f})\")\n",
    "    else:\n",
    "        print(\"\\nNo detection\")\n",
    "        pred_class_idx = 0  # Default to first class for demo\n",
    "else:\n",
    "    print(\"No test images available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GradCAM++\n",
    "target_layers = ['17', '20', '23']\n",
    "gradcam = YOLOv5GradCAMPlusPlus(model, target_layers)\n",
    "\n",
    "# Generate CAMs for all target layers\n",
    "print(\"Generating GradCAM++ visualizations...\")\n",
    "cams = gradcam.generate_all_cams(sample_image.image_path, pred_class_idx)\n",
    "\n",
    "# Load original image\n",
    "img = cv2.imread(sample_image.image_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Visualize CAMs for each layer\n",
    "fig, axes = plt.subplots(1, len(target_layers) + 1, figsize=(20, 5))\n",
    "\n",
    "# Original image\n",
    "axes[0].imshow(img)\n",
    "axes[0].set_title('Original Image', fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# CAM overlays\n",
    "for idx, (layer, (cam, metadata)) in enumerate(cams.items()):\n",
    "    overlay = gradcam.visualize_cam(img, cam, alpha=0.5)\n",
    "    axes[idx + 1].imshow(overlay)\n",
    "    axes[idx + 1].set_title(f'Layer {layer}\\nAOI_50: {metadata[\"aoi_50\"]:.3f}', fontsize=14)\n",
    "    axes[idx + 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nLayer-wise AOI_50 values:\")\n",
    "for layer, (_, metadata) in cams.items():\n",
    "    print(f\"  Layer {layer}: {metadata['aoi_50']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradCAM++ Visualization\n",
    "if model is not None:\n",
    "    # Real GradCAM++ with actual model\n",
    "    target_layers = ['17', '20', '23']\n",
    "    gradcam = YOLOv5GradCAMPlusPlus(model, target_layers)\n",
    "    \n",
    "    print(\"Generating GradCAM++ visualizations...\")\n",
    "    cams = gradcam.generate_all_cams(sample_image.image_path, pred_class_idx)\n",
    "    \n",
    "    # Load original image\n",
    "    img = cv2.imread(sample_image.image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "else:\n",
    "    # Demo mode - create synthetic visualizations\n",
    "    print(\"DEMO MODE: Showing synthetic GradCAM++ visualizations\")\n",
    "    print(\"With a real model, these would show actual attention patterns\")\n",
    "    \n",
    "    # Create a dummy image\n",
    "    img = np.ones((480, 640, 3), dtype=np.uint8) * 200\n",
    "    cv2.circle(img, (320, 240), 150, (100, 150, 200), -1)  # Simulate cornea\n",
    "    \n",
    "    # Create synthetic CAMs for demonstration\n",
    "    target_layers = ['17', '20', '23']\n",
    "    cams = {}\n",
    "    \n",
    "    for i, layer in enumerate(target_layers):\n",
    "        # Create progressively more focused attention maps\n",
    "        cam = np.zeros((480, 640), dtype=np.float32)\n",
    "        center_x, center_y = 320, 240\n",
    "        radius = 150 - i * 40  # Decreasing radius for deeper layers\n",
    "        \n",
    "        y, x = np.ogrid[:480, :640]\n",
    "        mask = (x - center_x)**2 + (y - center_y)**2 <= radius**2\n",
    "        cam[mask] = np.random.rand(*np.sum(mask)) * 0.5 + 0.5\n",
    "        \n",
    "        # Add some noise to make it realistic\n",
    "        cam = cv2.GaussianBlur(cam, (21, 21), 0)\n",
    "        \n",
    "        # Simulate metadata\n",
    "        metadata = {\n",
    "            'aoi_50': 0.3 - i * 0.08,  # Decreasing AOI for deeper layers\n",
    "            'layer': layer\n",
    "        }\n",
    "        \n",
    "        cams[layer] = (cam, metadata)\n",
    "\n",
    "# Visualize CAMs for each layer\n",
    "fig, axes = plt.subplots(1, len(target_layers) + 1, figsize=(20, 5))\n",
    "\n",
    "# Original image\n",
    "axes[0].imshow(img)\n",
    "axes[0].set_title('Original Image', fontsize=14)\n",
    "axes[0].axis('off')\n",
    "\n",
    "# CAM overlays\n",
    "for idx, (layer, (cam, metadata)) in enumerate(cams.items()):\n",
    "    # Create overlay\n",
    "    cam_resized = cv2.resize(cam, (img.shape[1], img.shape[0]))\n",
    "    cam_normalized = (cam_resized - cam_resized.min()) / (cam_resized.max() - cam_resized.min() + 1e-8)\n",
    "    \n",
    "    # Apply colormap\n",
    "    cam_colored = plt.cm.jet(cam_normalized)[:, :, :3]\n",
    "    overlay = img / 255.0 * 0.5 + cam_colored * 0.5\n",
    "    \n",
    "    axes[idx + 1].imshow(overlay)\n",
    "    axes[idx + 1].set_title(f'Layer {layer}\\nAOI_50: {metadata[\"aoi_50\"]:.3f}', fontsize=14)\n",
    "    axes[idx + 1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\nLayer-wise AOI_50 values:\")\n",
    "for layer, (_, metadata) in cams.items():\n",
    "    print(f\"  Layer {layer}: {metadata['aoi_50']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Batch Analysis - AOI Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze multiple images\n",
    "n_samples = min(20, len(test_images))  # Analyze first 20 images\n",
    "aoi_results = []\n",
    "\n",
    "print(f\"Analyzing {n_samples} images...\")\n",
    "for img_data in test_images[:n_samples]:\n",
    "    # Run inference\n",
    "    results = model.predict(img_data.image_path)\n",
    "    \n",
    "    if len(results['classes']) > 0:\n",
    "        pred_class = results['classes'][results['scores'].argmax()]\n",
    "        \n",
    "        # Generate CAM for layer 23 (most informative according to paper)\n",
    "        cam, metadata = gradcam.generate_cam(img_data.image_path, pred_class, '23')\n",
    "        \n",
    "        aoi_results.append({\n",
    "            'image': Path(img_data.image_path).name,\n",
    "            'true_class': img_data.class_name,\n",
    "            'pred_class': model.class_names[pred_class],\n",
    "            'correct': pred_class == img_data.label,\n",
    "            'aoi_50': metadata['aoi_50']\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_aoi = pd.DataFrame(aoi_results)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nSample results:\")\n",
    "print(df_aoi.head(10))\n",
    "\n",
    "# Plot AOI distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# AOI by class\n",
    "df_aoi.boxplot(column='aoi_50', by='true_class', ax=ax1, rot=45)\n",
    "ax1.set_title('AOI_50 Distribution by True Class')\n",
    "ax1.set_xlabel('Disease Class')\n",
    "ax1.set_ylabel('AOI_50')\n",
    "\n",
    "# AOI by correctness\n",
    "df_aoi.boxplot(column='aoi_50', by='correct', ax=ax2)\n",
    "ax2.set_title('AOI_50 by Prediction Correctness')\n",
    "ax2.set_xlabel('Correct Prediction')\n",
    "ax2.set_ylabel('AOI_50')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df_aoi.groupby('correct')['aoi_50'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cut-and-Paste Validation Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This requires cornea annotations\n",
    "# For demo purposes, we'll create a simple example\n",
    "\n",
    "from validation.cut_and_paste import CorneaAnnotation\n",
    "\n",
    "# Create sample annotation (you would load these from file)\n",
    "sample_annotation = CorneaAnnotation(\n",
    "    image_path=sample_image.image_path,\n",
    "    center_x=320,  # Example values\n",
    "    center_y=240,\n",
    "    major_axis=200,\n",
    "    minor_axis=180,\n",
    "    angle=0\n",
    ")\n",
    "\n",
    "# Initialize cut-and-paste validator\n",
    "cut_paste_validator = CutAndPasteValidator(model)\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread(sample_image.image_path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Extract cornea region\n",
    "cornea, mask = cut_paste_validator.extract_cornea(img_rgb, sample_annotation)\n",
    "\n",
    "# Visualize extraction\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].imshow(img_rgb)\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(mask, cmap='gray')\n",
    "axes[1].set_title('Cornea Mask')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cornea)\n",
    "axes[2].set_title('Extracted Cornea')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Cornea extraction complete!\")\n",
    "print(f\"Cornea region shape: {cornea.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Parameter Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive widget for exploring different layers\n",
    "from ipywidgets import interact, IntSlider, Dropdown\n",
    "\n",
    "def explore_gradcam(layer_idx=0, alpha=0.5):\n",
    "    \"\"\"Interactive function to explore GradCAM results\"\"\"\n",
    "    layer = target_layers[layer_idx]\n",
    "    \n",
    "    # Get CAM for selected layer\n",
    "    cam, metadata = cams[layer]\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Original image\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # CAM overlay\n",
    "    overlay = gradcam.visualize_cam(img, cam, alpha=alpha)\n",
    "    ax2.imshow(overlay)\n",
    "    ax2.set_title(f'Layer {layer} - AOI_50: {metadata[\"aoi_50\"]:.3f}')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create interactive widget\n",
    "interact(explore_gradcam,\n",
    "         layer_idx=IntSlider(min=0, max=len(target_layers)-1, step=1, value=0,\n",
    "                            description='Layer:'),\n",
    "         alpha=FloatSlider(min=0.0, max=1.0, step=0.1, value=0.5,\n",
    "                          description='Alpha:'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save analysis results\n",
    "output_dir = Path(\"demo_results\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save AOI results\n",
    "df_aoi.to_csv(output_dir / \"aoi_analysis.csv\", index=False)\n",
    "print(f\"AOI results saved to {output_dir / 'aoi_analysis.csv'}\")\n",
    "\n",
    "# Save sample visualization\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "overlay = gradcam.visualize_cam(img, cams['23'][0], alpha=0.5)\n",
    "ax.imshow(overlay)\n",
    "ax.set_title(f'{sample_image.class_name} - Layer 23 GradCAM++')\n",
    "ax.axis('off')\n",
    "plt.savefig(output_dir / \"sample_gradcam.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"Sample visualization saved to {output_dir / 'sample_gradcam.png'}\")\n",
    "\n",
    "# Summary report\n",
    "summary = {\n",
    "    \"n_images_analyzed\": len(df_aoi),\n",
    "    \"accuracy\": (df_aoi['correct'].sum() / len(df_aoi)),\n",
    "    \"mean_aoi_correct\": df_aoi[df_aoi['correct']]['aoi_50'].mean(),\n",
    "    \"mean_aoi_incorrect\": df_aoi[~df_aoi['correct']]['aoi_50'].mean(),\n",
    "    \"aoi_by_class\": df_aoi.groupby('true_class')['aoi_50'].mean().to_dict()\n",
    "}\n",
    "\n",
    "print(\"\\nAnalysis Summary:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Save to Google Drive if in Colab\n",
    "if IN_COLAB:\n",
    "    drive_path = \"/content/drive/MyDrive/YOLOv5_GradCAM_Results\"\n",
    "    !mkdir -p {drive_path}\n",
    "    !cp -r demo_results/* {drive_path}/\n",
    "    print(f\"\\nResults also saved to Google Drive: {drive_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 9. Conclusion\n\nThis demo notebook has shown how to use YOLOv5 GradCAM++ for anterior segment disease classification:\n\n1. **Setup on Google Colab**: Easy installation and configuration\n2. **Model Loading**: Load YOLOv5 model weights\n3. **GradCAM++ Visualization**: Generate attention maps for different layers\n4. **AOI_50 Analysis**: Calculate and compare attention metrics\n5. **Cut-and-Paste Demo**: Extract corneal regions for validation\n6. **Export Results**: Save results to Google Drive\n\n### Next Steps\n\n- Upload your own model weights and test images\n- Run the full analysis pipeline using `main.py`\n- Perform statistical tests on larger datasets\n- Compare with expert annotations\n\n### Resources\n\n- [Paper]: YOLOv5 Attention Analysis for Anterior Eye Disease Classification\n- [GitHub Repository]: https://github.com/kitaguchi77/yolov5-gradcam-corneai\n- [YOLOv5 Documentation]: https://github.com/ultralytics/yolov5\n\nFor questions or issues, please refer to the repository's issue tracker."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "This demo notebook has shown:\n",
    "\n",
    "1. How to load and use the YOLOv5 model for anterior segment disease classification\n",
    "2. How to generate and visualize Grad-CAM++ attention maps\n",
    "3. How to calculate AOI_50 metrics\n",
    "4. Basic cut-and-paste validation concepts\n",
    "5. How to analyze results and generate reports\n",
    "\n",
    "For full analysis including statistical tests and complete cut-and-paste validation, use the main.py script with appropriate data and annotations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}